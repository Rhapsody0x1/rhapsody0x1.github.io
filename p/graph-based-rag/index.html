<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="GraphRAG、LightRAG 和 HyperGraphRAG"><title>基于图的各种检索增强生成 (RAG) 方法</title><link rel=canonical href=https://rhapsody0x1.github.io/p/graph-based-rag/><link rel=stylesheet href=/scss/style.min.082fedb136661a23edf5653851d9aa837e69930ecf00772bb3625e21f42b7a6f.css><meta property='og:title' content="基于图的各种检索增强生成 (RAG) 方法"><meta property='og:description' content="GraphRAG、LightRAG 和 HyperGraphRAG"><meta property='og:url' content='https://rhapsody0x1.github.io/p/graph-based-rag/'><meta property='og:site_name' content="Rhapsody0x1's Blog"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='LLM'><meta property='article:tag' content='RAG'><meta property='article:tag' content='Paper'><meta property='article:published_time' content='2025-09-26T17:27:52+00:00'><meta property='article:modified_time' content='2025-09-26T17:27:52+00:00'><meta property='og:image' content='https://rhapsody0x1.github.io/p/graph-based-rag/cover.jpg'><meta name=twitter:title content="基于图的各种检索增强生成 (RAG) 方法"><meta name=twitter:description content="GraphRAG、LightRAG 和 HyperGraphRAG"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://rhapsody0x1.github.io/p/graph-based-rag/cover.jpg'><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu_b4d8dd0517cd0e70.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>Rhapsody0x1's Blog</a></h1><h2 class=site-description>逆行于人迹罕至之路❄️</h2></div></header><ol class=menu-social><li><a href=https://github.com/Rhapsody0x1 target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://im.qq.com/ target=_blank title=QQ rel=me><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-brand-qq"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M6 9.748a14.716 14.716.0 0011.995-.052c.275-9.236-11.104-11.256-11.995.052z"/><path d="M18 10c.984 2.762 1.949 4.765 2 7.153.014.688-.664 1.346-1.184.303C18.47 16.76 17.864 16.275 17 16"/><path d="M17 16c.031 1.831.147 3.102-1 4"/><path d="M8 20c-1.099-.87-.914-2.24-1-4"/><path d="M6 10c-.783 2.338-1.742 4.12-1.968 6.43-.217 2.227.716 1.644 1.16.917C5.488 16.86 6.09 16.413 7 16"/><path d="M15.898 13l-.476-2"/><path d="M8 20l-1.5 1c-.5.5-.5 1 .5 1h10c1 0 1-.5.5-1L16 20"/><path d="M13.75 7m-1 0a1 1 0 102 0 1 1 0 10-2 0"/><path d="M10.25 7m-1 0a1 1 0 102 0 1 1 0 10-2 0"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>首页</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>归档</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>搜索</span></a></li><li><a href=/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>友情链接</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-sun-high"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M14.828 14.828A4 4 0 109.172 9.172a4 4 0 005.656 5.656z"/><path d="M6.343 17.657l-1.414 1.414"/><path d="M6.343 6.343 4.929 4.929"/><path d="M17.657 6.343l1.414-1.414"/><path d="M17.657 17.657l1.414 1.414"/><path d="M4 12H2"/><path d="M12 4V2"/><path d="M20 12h2"/><path d="M12 20v2"/></svg>
<svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-moon-stars"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M12 3c.132.0.263.0.393.0a7.5 7.5.0 007.92 12.446A9 9 0 1112 2.992z"/><path d="M17 4a2 2 0 002 2 2 2 0 00-2 2 2 2 0 00-2-2 2 2 0 002-2"/><path d="M19 11h2m-1-1v2"/></svg>
<span>深色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives toc-widget"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#naiverag>NaiveRAG</a></li><li><a href=#graphrag>GraphRAG</a><ol><li><a href=#为什么要这么做>为什么要这么做？</a></li><li><a href=#那它是怎么做的>那它是怎么做的？</a></li><li><a href=#有什么问题>有什么问题？</a><ol><li><a href=#成本>成本</a></li><li><a href=#数据集>数据集</a></li></ol></li><li><a href=#一些缓解办法>一些缓解办法</a></li></ol></li><li><a href=#lightrag>LightRAG</a><ol><li><a href=#那它又是怎么做的>那它又是怎么做的？</a></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/graph-based-rag/><img src=/p/graph-based-rag/cover_hu_ddd3918c629cb39e.jpg srcset="/p/graph-based-rag/cover_hu_ddd3918c629cb39e.jpg 800w, /p/graph-based-rag/cover_hu_fbec0f935ee1e5a5.jpg 1600w" width=800 height=815 loading=lazy alt="Featured image of post 基于图的各种检索增强生成 (RAG) 方法"></a></div><div class=article-details><header class=article-category><a href=/categories/papers/ style=background-color:#2a9d8f;color:#fff>Papers</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/graph-based-rag/>基于图的各种检索增强生成 (RAG) 方法</a></h2><h3 class=article-subtitle>GraphRAG、LightRAG 和 HyperGraphRAG</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Sep 26, 2025</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 9 分钟</time></div><div><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-file-description"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M14 3v4a1 1 0 001 1h4"/><path d="M17 21H7a2 2 0 01-2-2V5a2 2 0 012-2h7l5 5v11a2 2 0 01-2 2z"/><path d="M9 17h6"/><path d="M9 13h6"/></svg>
<time class=article-time--words>4144 字</time></div></footer></div></header><section class=article-content><p>去年 4 月，微软在 Arxiv 上发表了 GraphRAG 的论文，并在 7 月将有关代码在 GitHub 上<a class=link href=https://github.com/microsoft/graphrag target=_blank rel=noopener>开源</a>出来，大约在 7 天内就拿到了 6.7k stars。而在今年暑假笔者恰好接触到了一些在实际生产环境中使用 RAG 系统的业务，因此尝试在这里追踪和解读一下基于图的 RAG 方法的学术研究。</p><h2 id=naiverag><a href=#naiverag class=header-anchor></a>NaiveRAG</h2><p>通常在各种论文里用 NaiveRAG 或者 BaselineRAG 表示最基础的 RAG 方法。<strong>RAG</strong> <em>(Retrieval-Augmented Generation, 检索增强生成)</em> 是一种设法将<strong>与问题相关的</strong>特定领域知识放入大模型上下文，从而使其能准确回答该领域问题的技术。其优势在于知识库规模不受大模型上下文长度制约，且无需在知识领域发生变化时重新调整模型本身，具有高度<strong>可扩展</strong>性。</p><p>好吧，这种定义性文字看着很头疼，所以让我们来换个角度。</p><ul><li><p>众所周知，大模型在回答专业领域问题时经常会出现<strong>幻觉</strong>而产生不准确的答案。</p></li><li><p>现在，你被安排做一个<strong>专门回答法律领域</strong>相关问题的聊天机器人。</p></li><li><p>如果机器人回答出错，你可能会<strong>被甲方青蒜</strong>。</p></li><li><p>你想到可以简单地把法律条文一股脑塞进问答的提示词 (Prompts) 里。</p></li><li><p>但一番尝试后你发现这根本行不通：</p><ul><li><p>法律条文太多，大模型上下文不够用；</p></li><li><p>就算够用，大模型的指令遵循等能力也会<strong>明显下降</strong>。</p></li></ul></li><li><p>你突然想到了平时使用的联网搜索功能，用联网搜索能解决这个问题吗？</p></li><li><p>甲方告诉你他们还有一些网上搜不到的<strong>内部</strong>文档，联网搜索也搞不定了。</p></li><li><p>那能不能在本地想办法构建一个“法律知识库”呢？</p></li><li><p>你试着把法律文档全部放到一起组成一个<strong>数据库</strong>。</p></li><li><p>然后你开始研究如何让大模型在回答问题前从数据库里<strong>搜索</strong>知识。</p></li></ul><p>恭喜你，你发明了最简单的检索增强生成方法——NaiveRAG。把过程分解成两步就是下面这样。</p><p>这是用文档建立知识库的流程：
<script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script><div data-mermaid-container style=border-radius:var(--card-border-radius)></div><script type=text/template data-mermaid-source>
    
graph TD;
    subgraph 构建知识库
        A(原始文档) --> B[文档分块];
        B --> C[嵌入知识块];
        C --> D[存入数据库];
        D --> E(建立索引);
    end


</script><script>(function(){const n=document.currentScript;if(!n)return;const e=n.previousElementSibling,t=e&&e.hasAttribute("data-mermaid-source")?e.previousElementSibling:null;if(!t)return;const s=e&&e.hasAttribute("data-mermaid-source")?e.textContent:"";function a(){return document.documentElement.dataset.scheme==="dark"?"dark":"default"}let r=a(),o={theme:r,logLevel:"fatal",securityLevel:"strict",startOnLoad:!1,arrowMarkerAbsolute:!1,er:{diagramPadding:20,layoutDirection:"TB",minEntityWidth:100,minEntityHeight:75,entityPadding:15,stroke:"gray",fill:"honeydew",fontSize:12,useMaxWidth:!0},flowchart:{diagramPadding:8,htmlLabels:!0,curve:"basis"},sequence:{diagramMarginX:50,diagramMarginY:10,actorMargin:50,width:150,height:65,boxMargin:10,boxTextMargin:5,noteMargin:10,messageMargin:35,messageAlign:"center",mirrorActors:!0,bottomMarginAdj:1,useMaxWidth:!0,rightAngles:!1,showSequenceNumbers:!1},gantt:{titleTopMargin:25,barHeight:20,barGap:4,topPadding:50,leftPadding:75,gridLineStartPadding:35,fontSize:11,fontFamily:'"Open-Sans", "sans-serif"',numberSectionStyles:4,axisFormat:"%Y-%m-%d",topAxis:!1}};function i(){if(!t||!s||!window.mermaid)return;mermaid.initialize(o),t.classList.add("mermaid"),t.removeAttribute("data-processed"),t.innerHTML=s,mermaid.init(0[0],t)}i(),window.addEventListener("onColorSchemeChange",e=>{o.theme=e&&e.detail==="dark"?"dark":"default",i()})})()</script></p><p>这是使用知识库来做回答的流程：
<script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script><div data-mermaid-container style=border-radius:var(--card-border-radius)></div><script type=text/template data-mermaid-source>
    
graph TD;
    subgraph 回答生成
        F(用户问题) --> G[寻找知识];
        E[数据库] -- 检索 --> G;
        G --> H[返回的知识块];
        F --> I[放入上下文];
        H --> I;
        I --> J[生成回答];
        J --> K(最终答案);
    end


</script><script>(function(){const n=document.currentScript;if(!n)return;const e=n.previousElementSibling,t=e&&e.hasAttribute("data-mermaid-source")?e.previousElementSibling:null;if(!t)return;const s=e&&e.hasAttribute("data-mermaid-source")?e.textContent:"";function a(){return document.documentElement.dataset.scheme==="dark"?"dark":"default"}let r=a(),o={theme:r,logLevel:"fatal",securityLevel:"strict",startOnLoad:!1,arrowMarkerAbsolute:!1,er:{diagramPadding:20,layoutDirection:"TB",minEntityWidth:100,minEntityHeight:75,entityPadding:15,stroke:"gray",fill:"honeydew",fontSize:12,useMaxWidth:!0},flowchart:{diagramPadding:8,htmlLabels:!0,curve:"basis"},sequence:{diagramMarginX:50,diagramMarginY:10,actorMargin:50,width:150,height:65,boxMargin:10,boxTextMargin:5,noteMargin:10,messageMargin:35,messageAlign:"center",mirrorActors:!0,bottomMarginAdj:1,useMaxWidth:!0,rightAngles:!1,showSequenceNumbers:!1},gantt:{titleTopMargin:25,barHeight:20,barGap:4,topPadding:50,leftPadding:75,gridLineStartPadding:35,fontSize:11,fontFamily:'"Open-Sans", "sans-serif"',numberSectionStyles:4,axisFormat:"%Y-%m-%d",topAxis:!1}};function i(){if(!t||!s||!window.mermaid)return;mermaid.initialize(o),t.classList.add("mermaid"),t.removeAttribute("data-processed"),t.innerHTML=s,mermaid.init(0[0],t)}i(),window.addEventListener("onColorSchemeChange",e=>{o.theme=e&&e.detail==="dark"?"dark":"default",i()})})()</script></p><p>网上有很多传统 RAG 方法的资料，包括怎么做嵌入，怎么做向量搜索，以后笔者可能会再单独写一篇文章聊 NaiveRAG，这里就先不赘述了。</p><h2 id=graphrag><a href=#graphrag class=header-anchor></a>GraphRAG</h2><p>原论文的 <a class=link href=https://arxiv.org/pdf/2404.16130 target=_blank rel=noopener>Arxiv 链接</a>。</p><p>GraphRAG 是微软开源的一套基于图结构的 RAG 方法。<a class=link href=https://microsoft.github.io/graphrag target=_blank rel=noopener>微软官方</a>的说法：</p><blockquote><p>GraphRAG is a structured, hierarchical approach to Retrieval Augmented Generation (RAG), as opposed to naive semantic-search approaches using plain text snippets. The GraphRAG process involves extracting a knowledge graph out of raw text, building a community hierarchy, generating summaries for these communities, and then leveraging these structures when perform RAG-based tasks.</p></blockquote><p>简单来说，它通过从文档中提取出“知识图谱”，并采用算法划分为社群，调用 LLM 为每个社群生成一份总结，在回答问题时分别在这些社群上生成一份答案，最终再使用 LLM 在这些回答的基础上生成最终答案。</p><h3 id=为什么要这么做><a href=#%e4%b8%ba%e4%bb%80%e4%b9%88%e8%a6%81%e8%bf%99%e4%b9%88%e5%81%9a class=header-anchor></a>为什么要这么做？</h3><p>在解释为什么要使用 GraphRAG 之前，我们可以先仔细审视传统 RAG 采用的方法，看看它有什么缺陷。</p><div class=table-wrapper><table><thead><tr><th>方法</th><th>缺陷</th><th>改进</th></tr></thead><tbody><tr><td>对文本进行分块后嵌入</td><td>知识被切断，导致文本块不能表示完整信息</td><td>适应文档的分块方法，如分隔符（对法律条文），或引入 LLM</td></tr><tr><td>采用向量化方法进行嵌入和匹配</td><td>对“关键词”的匹配能力非常弱</td><td>使用“混合检索”策略，即关键词相似度和向量相似度进行加权</td></tr><tr><td>基于相似度分数排序文本块</td><td>相似度得分无法完全表示和问题的相关程度</td><td>引入重排序模型 (Reranker)，代价是检索速度会明显变慢</td></tr><tr><td>直接用问题文本匹配文本块</td><td>多轮对话中由于代词等原因，召回率显著降低</td><td>利用 LLM 等进行查询重写，即构造出更容易检索知识的提问</td></tr></tbody></table></div><p>而 GraphRAG 指向了传统 RAG 的一个顽固问题：<strong>无法</strong>有效利用所有知识块，导致无法回答<strong>全局性</strong>的问题，例如“这些文档的主题是什么？”，传统 RAG 使用这个提问很难找到有效的知识块，因此也就很难合理地回答这个问题。</p><p>为了让大模型回答时能使用所有文本块提高的知识，提高答案的<strong>全面性</strong>，微软提出了 GraphRAG 的方法。</p><h3 id=那它是怎么做的><a href=#%e9%82%a3%e5%ae%83%e6%98%af%e6%80%8e%e4%b9%88%e5%81%9a%e7%9a%84 class=header-anchor></a>那它是怎么做的？</h3><p>GraphRAG 和传统 RAG 一样先采用<strong>固定长度</strong>分块法切分文本，然后按照下面的流程构建它的数据库：</p><ol><li><p>调用 LLM 为每个文本块提取<strong>实体</strong>和<strong>关系</strong>；</p><ul><li><p>例如：“库克在2025年发布了iPhone 17。”</p></li><li><p>实体：“库克”、“iPhone 17”</p></li><li><p>关系：“发布”</p></li></ul></li><li><p>通过<strong>所有</strong>的实体和关系构建一个<strong>图</strong>；</p></li><li><p>在这个图上运行 Leiden <strong>社区</strong>发现算法；</p></li><li><p>调用 LLM 为<strong>每个</strong>社区生成一份<strong>摘要</strong>；</p></li><li><p>将所有<strong>社区摘要</strong>存储作为数据库，这是将来用于检索的数据。</p></li></ol><p>执行询问时，其使用一个 <strong>Map-Reduce</strong> 流程：</p><ol><li><p>先在<strong>每个</strong>社区摘要上并行地为问题生成一个答案；</p></li><li><p>LLM 回答问题时会给出一个<strong>帮助性</strong>分数；</p></li><li><p>将帮助性分数<strong>最高</strong>的一些答案合并起来送入 LLM 上下文；</p></li><li><p>由 LLM 在此基础上生成一个最终的答案。</p></li></ol><p>总之它在构建知识库和回答问题的过程中都反复多次地调用 LLM 来处理数据，在它自己的 Benchmark，也就是“自适应测试集”评测下，微软认为这套方法明显地提高了 RAG 方法的<strong>全局感知</strong>能力。</p><h3 id=有什么问题><a href=#%e6%9c%89%e4%bb%80%e4%b9%88%e9%97%ae%e9%a2%98 class=header-anchor></a>有什么问题？</h3><h4 id=成本><a href=#%e6%88%90%e6%9c%ac class=header-anchor></a>成本</h4><p>笔者认为这套系统目前最显著的问题就是<strong>成本已经高昂到无法接受的地步</strong>。参考下面的B站视频：</p><div class=video-wrapper><iframe src="https://player.bilibili.com/player.html?as_wide=1&amp;high_quality=1&amp;page=1&bvid=BV1dZ421K7sz" scrolling=no frameborder=no framespacing=0 allowfullscreen></iframe></div><ul><li><p>使用云端 API，完整构建《圣诞颂歌》（约200页）的索引，回答“这个故事的主旨是什么”，总消费 <strong>11 美元</strong>。</p><ul><li><p>请求了 <strong>449</strong> 次 GPT-4 的 API，成本相对较低的嵌入模型仅调用了 <strong>19</strong> 次。</p></li><li><p>另外，根据笔者的经验，使用诸如轨迹流动这样的 API 平台可能还会严重地受到 <strong>Rate Limit</strong> 的限制。</p></li></ul></li><li><p>使用本地大模型，提取实体构建索引的时间<strong>极长</strong>。</p><ul><li>由于本地模型的性能限制，其可能<strong>无法</strong>输出正确的 JSON 格式结果导致嵌入过程失败。</li></ul></li></ul><p>另外，花费了如此庞大的代价构建索引后，如果还想加入新的文档，必须<strong>从头开始</strong>所有的嵌入过程。这在生产环境下几乎是不可接受的。</p><p>以上的原因直接导致了 GraphRAG 难以投入实际生产使用。</p><h4 id=数据集><a href=#%e6%95%b0%e6%8d%ae%e9%9b%86 class=header-anchor></a>数据集</h4><p>GraphRAG 的论文认为现有的测试集“不适用于<strong>全局感知</strong>任务评估”，因此<strong>完全没有</strong>在传统 RAG 使用的测试集上进行测试，而是自己设计了所谓的“自适应测试集”方法 (原文 Algorithm 1)：</p><ol><li><p>生成全局性的问题：</p><ol><li><p>向 LLM 提供对目标数据集的<strong>高层次描述</strong>及其<strong>用途</strong>。</p></li><li><p>要求 LLM 根据语料库的描述，生成 $K$ 个可能会使用该数据集的<strong>潜在用户画像</strong>。</p><ul><li>例如，对于播客文稿数据集，一个可能的用户画像是“寻找科技行业见解和趋势的科技记者” 。</li></ul></li><li><p>针对每一个生成的用户画像，继续要求 LLM 识别出该用户可能会使用这个数据集完成的 $N$ 个相关任务 。</p><ul><li>例如，对于“科技记者”这个用户，一个可能的任务是“了解科技领袖如何看待政策和监管的作用” 。</li></ul></li><li><p>最后，针对每一个<strong>用户-任务组合</strong>，提示 LLM 生成 $M$ 个高层次问题。这些问题满足：</p><ul><li><p>需要对整个语料库有全面的理解才能回答。</p></li><li><p>不能通过检索特定的、低层次的局部事实来回答。</p></li><li><p>例如，对于“科技记者”这个用户，一个可能的任务是“了解科技领袖如何看待政策和监管的作用” 。</p></li></ul></li><li><p>整理生成的所有问题，最终形成一个包含 $K×N×M$ 个问题的测试集，用于后续评估。</p><ul><li>在论文的实验中，研究人员设定 $K、N、M$ 均为 5，每个数据集共生成 125 个测试问题。</li></ul></li></ol></li><li><p>评估生成的答案：</p><ol><li><p>将测试集中的问题分别输入到 GraphRAG 和传统 RAG 系统中，获取答案。</p></li><li><p>将<strong>同一个</strong>问题和两个系统生成的答案同时提供给一个作为<strong>裁判</strong>的 LLM。即典型的 LLM-as-a-Judge 方法。</p></li><li><p>提示评估者 LLM 根据预设的评估标准，判断出赢家，或者平局。</p></li><li><p>记录胜负评估结果以及 LLM 给出的评判理由。为了保证结果的稳定性，每次比较都会重复多次并取平均值。</p></li></ol></li></ol><p>评估使用的 Prompt 如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-markdown data-lang=markdown><span class=line><span class=cl>---Role---
</span></span><span class=line><span class=cl>You are a helpful assistant responsible for grading two answers to a question that are provided by two
</span></span><span class=line><span class=cl>different people.
</span></span><span class=line><span class=cl>---Goal---
</span></span><span class=line><span class=cl>Given a question and two answers (Answer 1 and Answer 2), assess which answer is better according to
</span></span><span class=line><span class=cl>the following measure:
</span></span><span class=line><span class=cl>{criteria}
</span></span><span class=line><span class=cl>Your assessment should include two parts:
</span></span><span class=line><span class=cl><span class=k>-</span> Winner: either 1 (if Answer 1 is better) and 2 (if Answer 2 is better) or 0 if they are fundamentally
</span></span><span class=line><span class=cl>similar and the differences are immaterial.
</span></span><span class=line><span class=cl><span class=k>-</span> Reasoning: a short explanation of why you chose the winner with respect to the measure described above.
</span></span><span class=line><span class=cl>Format your response as a JSON object with the following structure:
</span></span><span class=line><span class=cl>{{
</span></span><span class=line><span class=cl>&#34;winner&#34;: &lt;1, 2, or 0&gt;,
</span></span><span class=line><span class=cl>&#34;reasoning&#34;: &#34;Answer 1 is better because &lt;your reasoning&gt;.&#34;
</span></span><span class=line><span class=cl>}}
</span></span><span class=line><span class=cl>---Question---
</span></span><span class=line><span class=cl>{question}
</span></span><span class=line><span class=cl>---Answer 1---
</span></span><span class=line><span class=cl>{answer1}
</span></span><span class=line><span class=cl>---Answer 2---
</span></span><span class=line><span class=cl>{answer2}
</span></span><span class=line><span class=cl>Assess which answer is better according to the following measure:
</span></span><span class=line><span class=cl>{criteria}
</span></span><span class=line><span class=cl>Output:
</span></span></code></pre></td></tr></table></div></div><p>其中的 <code>{criteria}</code> 部分内容如下，可以明显看出其对“全面性”的偏好性：</p><ul><li><strong>Comprehensiveness.</strong> How much detail does the answer provide to <u>cover all aspects</u> and details of the question?</li><li><strong>Diversity.</strong> How varied and rich is the answer in providing <u>different perspectives</u> and insights on the question?</li><li><strong>Empowerment.</strong> How well does the answer help the reader understand and make informed judgments about the topic?</li></ul><p>笔者认为，这一测试方法有明显的<strong>先射箭再画靶子</strong>的嫌疑。从目标 (提高回答全面性) 到测试集 (针对性的全局性提问) 到评估指标 (LLM裁判指标) 都是 GraphRAG 方法的“优势区间”。<del>说白了就是既当运动员又当裁判。</del></p><p>而且，仅在它的数据集上领先无法证明 GraphRAG 具有泛用性。</p><h3 id=一些缓解办法><a href=#%e4%b8%80%e4%ba%9b%e7%bc%93%e8%a7%a3%e5%8a%9e%e6%b3%95 class=header-anchor></a>一些缓解办法</h3><p>GraphRAG 目前在 GitHub 上还在进行活跃的更新。针对于上面的成本问题微软又提出了 LazyGraphRAG，不过笔者还没有仔细研究。</p><h2 id=lightrag><a href=#lightrag class=header-anchor></a>LightRAG</h2><p>来自香港大学的学者参考了 GraphRAG 采用图结构来存储知识库的思路，<strong>改良</strong>出了另一种基于图的 RAG 方法。其核心目的是解决 GraphRAG 在成本和效率上的短板。它省去了划分社区和生成摘要这两个成本极其高昂的步骤，改为使用一种基于<strong>双层关键词</strong>的范式。</p><h3 id=那它又是怎么做的><a href=#%e9%82%a3%e5%ae%83%e5%8f%88%e6%98%af%e6%80%8e%e4%b9%88%e5%81%9a%e7%9a%84 class=header-anchor></a>那它又是怎么做的？</h3><p>它和 GraphRAG 一样让 LLM 基于提示词提取实体关系，不过 LightRAG 使用的是一个<strong>三合一</strong>提示词，同时提取<strong>实体</strong>、<strong>关系</strong>和<strong>关键词</strong>。其中的关键词又分为高层关键词和低层关键词。</p><ul><li><p>高层关键词概括文本主题；</p></li><li><p>低层关键词概括实体关系。</p></li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-markdown data-lang=markdown><span class=line><span class=cl>-Goal-
</span></span><span class=line><span class=cl>Given a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the
</span></span><span class=line><span class=cl>identified entities.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>-Steps-
</span></span><span class=line><span class=cl><span class=k>1.</span> Identify all entities. For each identified entity, extract the following information:
</span></span><span class=line><span class=cl><span class=k>-</span> entity_name: Name of the entity, capitalized
</span></span><span class=line><span class=cl><span class=k>-</span> entity_type: One of the following types: [organization, person, geo, event]
</span></span><span class=line><span class=cl><span class=k>-</span> entity_description: Comprehensive description of the entity&#39;s attributes and activities
</span></span><span class=line><span class=cl>Format each entity as (&#34;entity&#34;&lt;/&gt;&lt;entity_name&gt;&lt;&gt;&lt;entity_type&gt;&lt;/&gt;&lt;entity_description&gt;)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>2.</span> From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are &#34;clearly related&#34; to each other.
</span></span><span class=line><span class=cl>For each pair of related entities, extract the following information:
</span></span><span class=line><span class=cl><span class=k>-</span> source_entity: name of the source entity, as identified in step 1
</span></span><span class=line><span class=cl><span class=k>-</span> target_entity: name of the target entity, as identified in step 1
</span></span><span class=line><span class=cl><span class=k>-</span> relationship_description: explanation as to why you think the source entity and the target entity are related to each other
</span></span><span class=line><span class=cl><span class=k>-</span> relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity
</span></span><span class=line><span class=cl><span class=k>-</span> relationship_keywords: one or more high-level key words that summarize the overarching nature of the relationship, focusing on concepts or themes rather than
</span></span><span class=line><span class=cl>specific details
</span></span><span class=line><span class=cl>Format each relationship as (&#34;relationship&#34;&lt;&gt;&lt;source_entity&gt;&lt;/&gt;&lt;target_entity&gt;&lt;&gt;&lt;relationship_description&gt;&lt;&gt;&lt;relationship_keywords&gt;&lt;&gt;&lt;relationship_strength&gt;)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>3.</span> Identify high-level key words that summarize the main concepts, themes, or topics of the entire text. These should capture the overarching ideas present
</span></span><span class=line><span class=cl>in the document.
</span></span><span class=line><span class=cl>Format the content-level key words as (&#34;content_keywords&#34;&lt;&gt;&lt;high_level_keywords&gt;)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>4.</span> Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use &#34;##&#34; as the list delimiter.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>5.</span> When finished, output &lt;COMPLETE&gt;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>-Real Data-
</span></span><span class=line><span class=cl>Entity_types: (entity_types)
</span></span><span class=line><span class=cl>Text: (input_text)
</span></span><span class=line><span class=cl>Output:
</span></span></code></pre></td></tr></table></div></div><p>还是和传统 RAG 一样，对文本进行分块，然后它的知识库构建过程是这样的：</p><ol><li><p>还是先提取实体和关系；</p></li><li><p>调用 LLM 使用上面的三合一 Prompt 为图中的<strong>每一个实体节点</strong>和<strong>每一个关系边</strong>都生成一个文本的“键值对”。</p><ul><li><p>其中，“键”是用于高效检索的<strong>关键词</strong>，而“值”是一段由 LLM 生成的<strong>总结性报告</strong> (<del>和GraphRAG殊途同归了属于是</del>)，用于后续的答案生成。</p><ul><li><p>对于实体节点来说，关键词是低层的；</p></li><li><p>对于关系边来说，关键词是高层的。</p></li></ul></li></ul></li><li><p>执行去重，识别和<strong>合并</strong>来自不同文本块的相同实体和关系 。</p><ul><li>目的是通过最小化图的规模来减少图操作的相关开销，从而实现更高效的数据处理 。</li></ul></li><li><p>最终被存入数据库的是<strong>知识图谱</strong>本身而非 GraphRAG 一样的各部分社区摘要。</p></li></ol><p>执行询问时，LightRAG 不会和 GraphRAG 一样进行很多次生成，而是执行下面的流程：</p><ol><li><p>从用户问题中<strong>提取</strong>双层关键词；</p><ul><li><p>低层关键词是指代具体实体、细节的词；</p></li><li><p>高层关键词是表示主题、概念的词。</p></li><li><p>例如，对于查询“国际贸易如何影响全球经济稳定？”</p><ul><li><p>高层关键词是“国际贸易”、“全球经济稳定”；</p></li><li><p>低层关键词可能是“贸易协定”、“关税”等。</p></li></ul></li></ul></li><li><p>在数据库中按<strong>向量</strong>方法检索关键词对应的关系边和实体节点；</p></li><li><p>对于找到的节点和边，收集被检索到的节点或边的<strong>一跳相邻节点</strong>；</p></li><li><p>把这些元素对应的<strong>总结性报告</strong>组装起来放入模型上下文；</p></li><li><p>由 LLM 以这部分上下文为依据生成最终答案。</p></li></ol><p>然后也是跑一趟微软的<strong>自适应测试集</strong>，在他们的论文里声称分数超过了原本的 GraphRAG 方法。</p></section><footer class=article-footer><section class=article-tags><a href=/tags/llm/>LLM</a>
<a href=/tags/rag/>RAG</a>
<a href=/tags/paper/>Paper</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section><section class=article-lastmod><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>最后更新于 Sep 26, 2025 17:27 UTC</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><script src=https://giscus.app/client.js data-repo=Rhapsody0x1/rhapsody0x1.github.io data-repo-id=R_kgDOPzFdKQ data-category=Announcements data-category-id=DIC_kwDOPzFdKc4CvwOk data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=light data-lang=en data-loading crossorigin=anonymous async></script><script>function setGiscusTheme(e){let t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:{setConfig:{theme:e}}},"https://giscus.app")}(function(){addEventListener("message",t=>{if(event.origin!=="https://giscus.app")return;e()}),window.addEventListener("onColorSchemeChange",e);function e(){setGiscusTheme(document.documentElement.dataset.scheme==="light"?"light":"dark")}})()</script><footer class=site-footer><section class=copyright>&copy;
2022 -
2025 Rhapsody0x1's Blog</section><section class=powerby>本博客主题效果基于 Stack 改进而来<br>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.31.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.eb17d74b8c8e4fde3237f8dddf0c0c24385f751f866798e5ada486ed1def0bb4.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>